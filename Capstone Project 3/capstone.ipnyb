### Capstone Project 3 Imannov Kaba - EDA (TRAVEL INSURANCE)
Importing libraries
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore") ##imported this to ignore all warnings
sns.set_theme()
from matplotlib.ticker import PercentFormatter


color_palette = ["#D81159", "#8F2D56", '#218380', '#FBB13C', '#73D2DE']
dark_color = ["#37371F", "#540804", '#BF6900', '#55505C', '#0C4767']
two_tone = [dark_color[2], color_palette[2]]
sns.palplot(color_palette)
sns.palplot(dark_color)
sns.palplot(two_tone)
df = pd.read_csv("data_travel_insurance.csv")
df_copy = df.copy() #always make a backup of a data
df.head(5)
print(f"This dataset consists of {df.shape[0]} rows and {df.shape[1]} columns.")
print("Columns of the dataset: ")
print("---"*20)
print(df.info())
df.describe(include=np.number).T #T here is to transpose. personal preference, feel free to delete the T to show the untransposed
Kesimpulan:
1. Net sales negative
2. Durasi negatif. Maximum durationnya sangat tinggi (bisa jadi outliers disebabkan oleh salah entry.)
3. Age paling tuanya 118 (bisa jadi disebabkan oleh salah entry)
df.describe(include='object').T
Kesimpulan:
1. Destinasinya sangat banyak 138 (very high cardinality)
2. Product name juga banyak 26 (high cardinality)
3. Gender banyak yang null

#cek jumlah data null di tabel
df.isna().sum()
#cek persentase null di gender
null_gender = df.Gender.isna().sum()/len(df.Gender)

print(f"{round(null_gender*100,3)} % of the data is missing for the Gender column.")
#data null di gender ini akan diisi dengan 'Unidentified' karena kita belum tau Gender ini penting atau engga
#Kalo ga penting nanti tinggal di drop saja

df["Gender"].fillna("Not Specified", inplace=True)
df.head()
#cek data duplicate
print(f"Number of duplicated rows: {df.duplicated().sum()}")
#drop duplicate data
df.drop_duplicates(inplace=True)
print(f"Number of duplicated rows: {df.duplicated().sum()}")
#karena kolom Claim itu kategorikal, dengan unique valuesnya 2 aja, kemungkinannya hanya Yes & No, kita bakal ubah jadi binary
df['Claim'] = df['Claim'].apply(lambda x: 1 if x=='Yes' else 0)
#kita mau cek disini 1 berarti yes, 0 berarti no
print(f'There are {len(df[df["Claim"]==0])} Rejected claims')
print(f'There are {len(df[df["Claim"]==1])} Accepted claims')
sns.countplot(x=df["Claim"], color=color_palette[2]).set_title("Customer Claims")
Datanya imbalanced, yang berarti "Minority class classification"
#### Net Sales - Commission
#kita coba cek Net Sales & Commission, apakah berkorelasi
df["Net Sales"].corr(df["Commision (in value)"])
Nggak besar nilai korelasinya tapi jelas berkorelasi.
Net sales nggak boleh lebih kecil dari commission, karena biasanya commission itu diwakilin dari fungsi net sales
#ngecek nilai sales apakah ada yang lebih kecil dari commission atau ngga
df_sales_commision = df[df["Net Sales"]<df["Commision (in value)"]]
df_sales_commision.sample(10)
dan ternyata ada.
#ngecek distribusi net sales
sns.histplot(data=df_sales_commision, x="Net Sales",binwidth=100, color=color_palette[1])
# Asumsikan kita sudah meng-define 'df_sales_commision' DataFrame
print(f"There are {len(df_sales_commision)} records")
print(f'{len(df_sales_commision[df_sales_commision["Claim"] == 0])} unclaimed insurances')
print(f'{len(df_sales_commision[df_sales_commision["Claim"] == 1])} claimed insurances')
result = df_sales_commision.groupby(by='Claim')[["Net Sales", "Commision (in value)"]].sum()
print(result)

#karena nilainya 0, kita bakal drop
drop_netsales = list(df_sales_commision.index.values)
df.drop(index=drop_netsales, inplace = True)
#### Age
sns.histplot(data=df, x="Age",binwidth=10, color=color_palette[3])
df_old = df[df['Age']>80]
print(f"There are {len(df_old)} people over 80 in the records")

print(f'{len(df_old[df_old["Claim"]==0])} of them havent claimed insurances')
print(f'{len(df_old[df_old["Claim"]==1])} of them have claimed insurances')
ax = sns.histplot(data=df_old, x="Age",binwidth=5, color=color_palette[4])
ax.bar_label(ax.containers[0])
#cek persentase orang tua
(len(df_old)/len(df))*100
Dari persentase keliatan bahwa jumlah orang tua itu sedikit, dan kalo dari grafik, keliatan bahwa kita nggak ada value di umur 95-115. Bisa diasumsikan kalo yang umur 120 itu salah input (nggak masuk akal juga jumlahnya). Jadi kita bakal drop yang 120
df_old = df[df['Age']>115]
df.drop(index=df_old.index.values, inplace = True)
#### Duration
df['Duration'].describe().T
Nilai minimum nya 0 hari. Travel insurance yang nilainya 0 hari itu tidak wajar
result = df[df['Duration'] == 0].groupby(by='Claim')[["Net Sales", "Commision (in value)"]].sum()
print(result)

Dari sini keliatan bahwa yang durationnya 0, nilai claimnya semuanya 0 yang mana berarti claimnya di reject. Jadi kita drop saja
#cek dulu jumlahnya
len(df[df['Duration']==0])
#mari kita drop
df.drop(index=df[df['Duration']==0].index.values, inplace = True)
#plot lagi
sns.histplot(data=df, x="Duration",binwidth=100, color=color_palette[4])
Setahun ada 365 hari, kita coba cek apakah ada yang diatas 365. Agak aneh, siapa tahu outliers
df_duration = df[df['Duration']>365]
ax = sns.histplot(data=df_duration, x="Duration",binwidth=500, color=color_palette[4])
ax.bar_label(ax.containers[0])
Ada 12 yang diatas 365. Kita bakal drop ini karena kemungkinan besar data entry error
df.drop(index=df[df['Duration']>400].index.values, inplace = True)
#### Gender
numeric_columns = df.select_dtypes(include=['int64', 'float64'])

# Include the 'gender' column
filtered_df = pd.concat([df['Gender'], numeric_columns], axis=1)

# Now 'filtered_df' will only contain 'gender' and numeric columns
print(filtered_df)
filtered_df.groupby(by='Gender').mean()
filtered_df.groupby(by='Gender').describe().T
Tidak ada perbedaan signifikan di gender untuk claim dan fitur lain. Kita bakal drop gender di dataframe utama (df)
df.drop('Gender', axis=1, inplace = True)
#### Destination
Karena tadi di kolom destination cardinalitynya tinggi, kita bakal coba pakai prinsip Pareto untuk mengurangi cardinality
df['Destination'].unique()
#pakai crosstab function buat liat destination mana yang claimnya lebih banyak oke in
destinations=pd.crosstab(df["Destination"],df["Claim"]).sort_values(by=0, ascending = False)
destinations.head(20)
destinations.describe().T
#prinsip pareto
destinations["Total_Claim"] = destinations[0] + destinations[1]
destinations.head()
destinations["Cum_Percentage"] = round(destinations["Total_Claim"].cumsum()/destinations["Total_Claim"].sum()*100,2)
top_destinations = destinations.sort_values(by = "Total_Claim", ascending = False).head(50) 
# Set figure and axis
fig, ax = plt.subplots(figsize=(22,10))

# Plot bars (i.e. frequencies)
ax.bar(top_destinations.index, top_destinations["Total_Claim"],color=color_palette[2])
ax.set_title("Pareto Chart")
ax.set_xlabel("Destination")
ax.set_ylabel("Frequency")
plt.xticks(rotation=90)

# Second y axis (i.e. cumulative percentage)
ax2 = ax.twinx()
ax2.plot(top_destinations.index, top_destinations["Cum_Percentage"], color="red", marker="D", ms=7)
ax2.axhline(80, color=dark_color[2], linestyle="dashed")
ax2.yaxis.set_major_formatter(PercentFormatter())
ax2.set_ylabel("Cumulative Percentage")
Dari pareto chart, keliatan dia crossing di India.
destinations_to_grp = top_destinations.index[:13].values
destinations_to_grp
df['Destination'] = df['Destination'].apply(lambda x: 'Other_Destination' if x not in destinations_to_grp else x)
df['Destination'].unique()
#### Product Name
df['Product Name'].unique()
numeric_columns = df.select_dtypes(include=['int64', 'float64'])

# Include the 'gender' column
filtered_df = pd.concat([df['Product Name'], numeric_columns], axis=1)

# Now 'filtered_df' will only contain 'gender' and numeric columns
print(filtered_df)
filtered_df.groupby(by='Product Name').mean()
products = pd.crosstab(filtered_df["Product Name"],filtered_df["Claim"]).sort_values(by=0, ascending = False)
products
products["Total_Claim"] = products[0] + products[1]
products["Cum_Percentage"] = round(products["Total_Claim"].cumsum()/products["Total_Claim"].sum()*100,2)
# Set figure and axis
fig, ax = plt.subplots(figsize=(22,10))

# Plot bars (i.e. frequencies)
ax.bar(products.index, products["Total_Claim"],color=color_palette[2])
ax.set_title("Pareto Chart")
ax.set_xlabel("Destination")
ax.set_ylabel("Frequency")
plt.xticks(rotation=90)

# Second y axis (i.e. cumulative percentage)
ax2 = ax.twinx()
ax2.plot(products.index, products["Cum_Percentage"], color="red", marker="D", ms=7)
ax2.axhline(80, color=dark_color[2], linestyle="dashed")
ax2.yaxis.set_major_formatter(PercentFormatter())
ax2.set_ylabel("Cumulative Percentage");
products_to_grp = products.index[:5].values
products_to_grp
Dari pareto chart, ~80% dari total claim nya :
1. Cancellation Plan
2. 2-way comprehensive plan
3. Rental Vehicle excess insurance
4. basic plan
5. bronze plan

yang lainnya bakal kita masukin ke 'Other' category.
df['Product Name'] = df['Product Name'].apply(lambda x: 'Other_Product' if x not in products_to_grp else x)
df['Product Name'].unique()
#### Agency
df['Agency'].unique()
numeric_columns = df.select_dtypes(include=['int64', 'float64'])

# Include the 'gender' column
filtered_df = pd.concat([df['Agency'], numeric_columns], axis=1)

# Now 'filtered_df' will only contain 'gender' and numeric columns
print(filtered_df)
filtered_df.groupby(by='Agency').mean()
agencies = pd.crosstab(filtered_df['Agency'],filtered_df['Claim']).sort_values(by=0, ascending = False)
agencies
agencies["Total_Claim"] = agencies[0] + agencies[1]
agencies["Cum_Percentage"] = round(agencies["Total_Claim"].cumsum()/agencies["Total_Claim"].sum()*100,2)
# Set figure and axis
fig, ax = plt.subplots(figsize=(22,10))

# Plot bars (i.e. frequencies)
ax.bar(agencies.index, agencies["Total_Claim"],color=color_palette[2])
ax.set_title("Pareto Chart")
ax.set_xlabel("Destination")
ax.set_ylabel("Frequency")
plt.xticks(rotation=90)

# Second y axis (i.e. cumulative percentage)
ax2 = ax.twinx()
ax2.plot(agencies.index, agencies["Cum_Percentage"], color="red", marker="D", ms=7)
ax2.axhline(80, color=dark_color[2], linestyle="dashed")
ax2.yaxis.set_major_formatter(PercentFormatter())
ax2.set_ylabel("Cumulative Percentage");
agencies_to_grp = agencies.index[:3].values
agencies_to_grp
Selain EPX, C2B, dan CWT, kita masukin ke Others
df['Agency'] = df['Agency'].apply(lambda x: 'Other_Agency' if x not in agencies_to_grp else x)
df['Agency'].unique()
#### Modeling
df.head()
categoricals=list(df.select_dtypes(include=["object"]).columns)
categoricals
##### One Hot Encoding
#OHE ke categorical data
one_hot=pd.get_dummies(data=df, columns=categoricals)
one_hot.head()
#kita liat list kolom yang di OHE
print(*list(one_hot.columns), sep="\n")
one_hot['Claim'].value_counts()
#kita mau dapetin nilai yang di reject biar sama kaya yang di accept yaitu 663
sample_reject = one_hot[one_hot['Claim']==0].sample(663)
sample_reject.head()
#kita concat yang claim di reject sama di accept
res = pd.concat([sample_reject, one_hot[one_hot['Claim']==1]], axis=0)
res['Claim'].value_counts()
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import train_test_split
X = res.drop(["Claim"], axis=1)
y = res["Claim"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=47)
#### Logistic Regression
model = LogisticRegression()
model.fit(X_train,y_train)
preds=model.predict(X_test)

print(f1_score(y_test, preds))
print(accuracy_score(y_test,preds))

# Classification report
print(classification_report(y_test, preds, digits=4))
##### Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier

model_DT= DecisionTreeClassifier()
model_DT.fit(X_train,y_train)
pred_DT=model_DT.predict(X_test)
print(f1_score(y_test,pred_DT))
print(accuracy_score(y_test,pred_DT))
##### Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier 

model_rf= RandomForestClassifier(random_state=1)
model_rf.fit(X_train,y_train)
pred_rf=model_rf.predict(X_test)
print(f1_score(y_test,pred_rf))
print(accuracy_score(y_test,pred_rf))
f1_score(y_test, preds, average='macro')
